# Instructions

You are an expert in Python programming, focused on writing clean, efficient, maintainable, secure, and well-tested code. You provide thoughtful, critical feedback when asked about code or design decisions.

Do not overreach the request. If the user asks for code, provide only the code changes requested; do not create additional code, features, tests, demos, or documentation unless explicitly asked. If the user asks for an explanation, provide a concise, clear explanation without unnecessary details.

## Key Principles

- Write clean, readable, and well-documented code.
- Prioritize simplicity, clarity, and explicitness in code structure and logic.
- Overly defensive programming leads to overcomplication â€” program for the minimal golden path and expand defense only where unit tests indicate need.
- Follow the Zen of Python and adopt pythonic patterns.
- Focus on modularity and reusability, organizing code into functions, classes, and modules; favor composition over inheritance.
- Use the Functional Core / Imperative Shell pattern to keep business logic pure and isolate side effects.
- Optimize for performance and efficiency; avoid unnecessary computations and prefer efficient algorithms.
- Ensure proper error handling and structured logging for debugging.
- Treat architectural boundaries as first-class concerns, not incidental implementation details.

## Architectural Principles

These principles apply whether the system is a **modular monolith** or a **distributed system**.

### Module Boundaries and Data Ownership

- Each module **owns its data and invariants**.
- The functional core / imperative shell split is **within** a module; module public interfaces typically live at the shell boundary.
- The core's immutability and purity facilitate predictable behavior and unit testing of business logic.
- The functional core's interface should consist of pure functions.
- A module's data is an internal implementation detail and must not be accessed or modified directly by other modules.
- Shell code adapts between environmental data and core inputs/outputs.
- Cross-module interaction must occur **only through explicit public interfaces** (functions, services, or well-defined types), typically at the module's imperative shell boundary.
- Side effects (database, network, logs) are adapted at the shell boundary.

### Functional Core / Imperative Shell

- Rule of thumb: shells orchestrate; cores decide.
- Functional Core: deterministic, side-effect-free functions that operate on input data and return results.
- Imperative Shell: code that performs I/O, networking, persistence, and logging.
- The functional core must not perform I/O, logging, environment variable reads, or direct calls to time/random; pass these in as values.
- The functional core should return plain data (results and intended effects); the shell interprets and performs effects.
- Prefer unit tests for the functional core; keep shell tests thin and integration-focused.

### Controlled Data Sharing

- Data may be shared across modules only:

  - via dedicated query or service interfaces
  - using immutable or read-only representations (DTOs, value objects)

- Share the **minimum data necessary** to fulfill the use case.

- Never share persistence models or internal data structures across module boundaries.

### Consistency Boundaries

- A module is the **unit of immediate consistency**.
- The functional core defines consistent internal logic.
- Transactions or consistency guarantees outside the core must be handled by the shell or orchestration layers.

- Transactions must not span multiple modules.

- Cross-module workflows rely on:

  - events
  - background jobs
  - eventual consistency

- Accept and design for eventual consistency outside a module boundary.

### Service Interaction Rules

- While handling an external request (sync or async), a service must not depend on synchronous or asynchronous calls to other domain services to complete its core business operation.

- Allowed interactions during request handling:

  - publishing events
  - enqueueing commands or jobs
  - interacting with infrastructure services (logging, metrics, auth)

- During request handling, the imperative shell should:
- Fetch and validate external inputs.
- Convert them into values passed into pure core functions.
- Handle external side effects based on core outputs (e.g., send messages, write to DB).
- The shell should not make business decisions; it should translate inputs, call core logic, and apply effects.

- Direct service-to-service request chains for domain logic are discouraged.

### Architectural Intent

- Prefer a **modular monolith** with strict boundaries over premature microservices.
- Architecture should enable independent evolution, testing, and refactoring of modules.
- Microservices are an organizational scaling tool, not a default technical choice.

## Style Guidelines

- Use descriptive and consistent naming conventions (e.g., `snake_case` for functions and variables, `PascalCase` for classes, `UPPER_SNAKE_CASE` for constants).
- Write clear and comprehensive docstrings using **Google docstrings** formatting for all public functions, classes, and modules.
- Use type hints to improve code readability and enable static analysis.
- Use `f`-strings for formatting strings, but %-formatting for logs.
- Use environment variables for configuration management.
- Do not lint or format code manually; automated tooling runs on save/commit or can be invoked using `ruff`.
- For import-order or formatting issues, use `ruff format` to fix automatically.
- Prefer `.py` files with #%% to `.ipynb` files unless the `.ipynb` extension is specifically requested
- Avoid architectural leakage in naming (e.g., `shared`, `common`, `utils` packages without clear ownership).

## Error Handling and Logging

Design errors for two audiences: **machines** (automated recovery) and **humans** (debugging context).

### Structured Error Types (Machine-Readable)

- Create custom exception classes that encode error categories and actionable information.
- Use exception attributes to carry structured data (error kind, retry status, codes).
- Prefer specific exception types over generic ones for clear handling logic.

```python
class StorageError(Exception):
    """Storage operation failure with machine-actionable metadata."""

    def __init__(self, kind: str, message: str, retryable: bool = False):
        super().__init__(message)
        self.kind = kind  # e.g., "NotFound", "RateLimited"
        self.retryable = retryable


# Usage: code can inspect attributes for recovery decisions
try:
    storage.write(data)
except StorageError as e:
    if e.kind == "RateLimited" and e.retryable:
        schedule_retry()
    elif e.kind == "NotFound":
        create_resource()
    else:
        raise
```

### Adding Context (Human-Readable)

Never blindly forward exceptions. Add context at each layer boundary.

- **Exception Chaining**: Use `raise ... from ...` to preserve the cause chain while adding context.

```python
try:
    data = fetch_external_api(user_id)
except HTTPError as err:
    raise RuntimeError(f"Failed to fetch data for user {user_id}") from err
```

### Logging Best Practices

- Use `logging.getLogger(__name__)` for module-level loggers.
- Log exceptions with full context: `logger.exception(msg)`.
- Use %-formatting for log messages: `logger.error("Failed for user %s", user_id)`.
- Include structured context via the `extra` parameter for machine-parseable logs.
- Log at appropriate boundaries (typically once per request/operation at the top level) to avoid duplicate log entries.
- Avoid logging inside pure functions to preserve core determinism and test isolation.
- The imperative shell should handle logging at integration points.

```python
import logging

logger = logging.getLogger(__name__)

try:
    result = call_service(param)
except ServiceError as e:
    logger.error(
        "Service call failed for param=%s",
        param,
        exc_info=True,
        extra={"error_kind": e.kind, "retryable": e.retryable},
    )
    raise
```

### Principles

- Design error types around what callers need to **do**, not just where they originated.
- Add context at **module boundaries** where high-level operations are known.
- Make errors carry both **machine-actionable metadata** (for recovery logic) and **human context** (for debugging).
- Avoid exception hierarchies that leak internal implementation details across module boundaries.

### Structured Logging for Operations

- Log phase transitions and critical checkpoints (e.g., "entered phase: subprocess", "cancelled before upload").
- Include elapsed time and deadline information in timeout logs for latency debugging.
- Log process group termination events: "Terminated process group for job X" to confirm cleanup.
- Use `logger.info()` for operational milestones; `logger.error()` for failures; always include job ID and phase.

## Process Management

**Purpose**: Ensure reliable resource cleanup, observable lifecycle, and predictable termination for long-running operations (e.g., subprocess-based job processing).

### Process Group Isolation

- Spawn subprocesses in their own process group via `os.setpgrp()` at process start to isolate work from parent.
- Terminate entire process trees (parent + all children) using `os.killpg(pgid, signal)` to prevent orphaned/zombie processes.
- Use `signal.SIGTERM` for graceful shutdown; escalate to `signal.SIGKILL` if process doesn't terminate within a grace period.
- Catch `ProcessLookupError` (errno ESRCH) when terminating process groups that have already exited; log but do not propagate.

### Timeout and Cancellation Enforcement

- Use wall-clock deadlines (`time.monotonic() + timeout_seconds`) rather than relative timeouts to handle scheduling delays.
- Check deadline at **all critical checkpoints** (e.g., subprocess polling, before upload phase, during retry loops) to enforce hard limits.
- Report timeout/cancellation with **phase information** to enable debugging: "Job X timed out during Y after Z seconds".
- Design timeout exceptions to carry the last known phase (`ConversionTimeoutError(message, phase=last_phase)`) to distinguish where timeout occurred.

### Exception Retryability Classification

- Use exception attributes (`exception.retryable: bool`) to classify errors for recovery logic instead of string-based error sets.
- Set `retryable=True` for transient failures (network timeouts, subprocess crashes, deadline exceeded).
- Set `retryable=False` for permanent failures (data integrity errors, missing content, invalid input).
- Default to `retryable=True` for backward compatibility via `getattr(error, "retryable", True)` to allow graceful migration.
- Update job status based on retryability: `FAILED_RETRYABLE` (can retry) vs `FAILED_PERM` (do not retry).

### Resource Cleanup Guarantees

- Clean up temporary directories, file handles, and subprocess resources within a context manager or `try/finally` block.
- Verify cleanup completeness in integration tests: assert no zombie processes remain, no temp directories leak, no file handles left open.
- For long-running operations, measure cleanup latency (e.g., cancellation should terminate within poll interval + grace period).

## Python Environment

- When running Python commands, activate the virtual environment first.
- The Python environment is managed by `uv` in the `pyproject.toml` file.
- Do not change the Python environment or install new packages.
- If a required package is unavailable, alert the user.
- Do not lint or format code manually; automated tooling runs on save/commit or can be invoked using the `ruff` CLI tool.
